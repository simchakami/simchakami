{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse \n",
    "from urllib import parse\n",
    "import os, sys\n",
    "\n",
    "import random\n",
    "\n",
    "# URL = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
    "\n",
    "def get_url(URL):\n",
    "    if requests.get(URL).status_code == 200:\n",
    "        soup = BeautifulSoup(requests.get(URL).text, \"html.parser\")\n",
    "        return soup\n",
    "    else:\n",
    "        return 'ERROR'\n",
    "\n",
    "\n",
    "def download_link(soup, URL, page_num=5):\n",
    "    link_list = []\n",
    "    # prefix = 'https://en.wikipedia.org/'\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if  link['href'].startswith(\"/\") and not ':' in link['href']:\n",
    "            link_list.append(urljoin(URL, link['href']))\n",
    "    return link_list\n",
    "    # choiced_links = random.choices(link_list, k = min(page_num, len(link_list)))\n",
    "    # return choiced_links\n",
    "\n",
    "def download_img(soup, URL, image_num):\n",
    "    choiced_imeges = random.choices(soup.find_all(\"img\", src = True, alt = True), k = min(image_num, len(soup.find_all(\"img\", src = True, alt = True))))\n",
    "    img_list = []\n",
    "    filename_list = []\n",
    "    # for img in soup.find_all('img', src=True , alt=True):\n",
    "    for img in choiced_imeges:\n",
    "        img_list.append(urljoin(URL, img['src']))\n",
    "        filename_list.append(img['alt'])\n",
    "        parsed_url = urlparse(URL)\n",
    "        base_domain = parsed_url.path\n",
    "        # print(parsed_url)\n",
    "        folder_name = base_domain.replace(\"/\", \"_\")\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        \n",
    "        for i, img in enumerate(img_list):\n",
    "            filename = f\"image_{filename_list[i]}.jpg\"\n",
    "            filepath = os.path.join(folder_name, filename)\n",
    "            urllib.request.urlretrieve(img, filepath)\n",
    "          \n",
    "   \n",
    "\n",
    "# download_img(get_url(URL), image_num=5)\n",
    "# download_link(get_url(URL), URL, page_num=5)\n",
    "\n",
    "def donlowedr(URL, page_num=5, lavel_num=5, image_num=5):\n",
    "    soup = get_url(URL)\n",
    "    download_img(soup, URL, image_num =5)\n",
    "    link_list = download_link(soup, URL, page_num=5)\n",
    "    # for link in link_list:\n",
    "    #     soup = get_url(str(link))\n",
    "    #     download_img(soup, str(link), image_num =5, lavel_num=(lavel_num-1))\n",
    "    if lavel_num > 0:\n",
    "        print(lavel_num)\n",
    "        for link in link_list:\n",
    "            donlowedr(str(link), page_num=5, lavel_num = (lavel_num-1), image_num=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donlowedr(\"https://en.wikipedia.org/wiki/Python_(programming_language)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
