{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://en.wikipedia.org/wiki/Web_scraping', 'https://en.wikipedia.org/wiki/Dataplot', 'https://en.wikipedia.org/wiki/Generative_adversarial_network', 'https://en.wikipedia.org/wiki/LLVM', 'https://en.wikipedia.org/wiki/Python_(programming_language)']\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'en.wikipedia.org/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9985/2735352733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# for link in link_list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# donlowedr(donlowedr(str(link), page_num, lavel_num = (lavel_num-1), image_num = 5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mdonlowedr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://en.wikipedia.org/wiki/Python_(programming_language)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9985/2735352733.py\u001b[0m in \u001b[0;36mdonlowedr\u001b[0;34m(url, page_num, lavel_num, image_num)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdonlowed_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# if lavel_num > 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# for link in link_list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9985/2735352733.py\u001b[0m in \u001b[0;36mdonlowed_img\u001b[0;34m(soup, url, image_num, page_folder)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Handle temporary file setup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mtfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mtfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'en.wikipedia.org/'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from urllib import parse\n",
    "import urllib.request\n",
    "import os\n",
    "import textwrap\n",
    "import setuptools\n",
    "import random\n",
    "\n",
    "# url = (\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
    "\n",
    "def get_soup(url):\n",
    "    if requests.get(url).status_code == 200:\n",
    "        soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "        return soup\n",
    "    else:\n",
    "        return \"EOFError\" #how to return erorr how breakes the program?\n",
    "\n",
    "def get_links(soup, url, page_num = 5):\n",
    "    \n",
    "    link_list = []\n",
    "    for link in soup.find_all(\"a\", href = True):\n",
    "        if link[\"href\"].startswith(\"/\") and not \":\" in link[\"href\"]:\n",
    "            link_list.append(urljoin(url, link[\"href\"]))\n",
    "    choiced_links = random.choices(link_list, k = min(page_num, len(link_list)))\n",
    "    return choiced_links\n",
    "\n",
    "def donlowed_img(soup, url, image_num, page_folder):\n",
    "    #choiced_imeges = set()\n",
    "    if not os.path.exists(page_folder):\n",
    "        os.mkdir(page_folder) \n",
    "    #choiced_imeges.add(soup.find_all(soup.find_all(\"img\", src = True)))\n",
    "    choiced_imeges = random.choices(soup.find_all(\"img\", src = True), k = min(image_num, len(soup.find_all(\"img\", src = True))))\n",
    "    for image in choiced_imeges:  \n",
    "        file_name = image[\"alt\"] #simcha\n",
    "        file_url = urljoin(url, image[\"src\"])\n",
    "        file_path = os.path.join(page_folder, file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "\n",
    "        \n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "\n",
    "\n",
    "            # with open(file_path, 'wb') as file:\n",
    "            #     file_bin = requests.session.get(file_url)\n",
    "            #     file.write(file_bin)\n",
    "\n",
    "\n",
    "\n",
    "def donlowedr(url, page_num = 5, lavel_num = 5, image_num = 5):\n",
    "    soup = get_soup(url)\n",
    "    link_list = get_links(soup, url, page_num=5)\n",
    "    print(link_list)\n",
    "    for link in link_list:\n",
    "        soup = get_soup(str(link))\n",
    "        donlowed_img(soup, str(link), image_num = 5, page_folder = urlparse(url).netloc)\n",
    "    # if lavel_num > 0:\n",
    "        # for link in link_list:\n",
    "        # donlowedr(donlowedr(str(link), page_num, lavel_num = (lavel_num-1), image_num = 5))\n",
    "donlowedr(\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9985/3833345657.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://en.wikipedia.org/wiki/Python_(programming_language)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#get_links(url, get_soup(url))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdonlowed_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9985/3833345657.py\u001b[0m in \u001b[0;36mdonlowed_img\u001b[0;34m(url, soup, image_num, page_folder)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mimage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#choiced_imeges = set()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#choiced_imeges.add(soup.find_all(soup.find_all(\"img\", src = True)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import urllib.request\n",
    "import os\n",
    "import textwrap\n",
    "import setuptools\n",
    "import random\n",
    "\n",
    "#url = (\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
    "\n",
    "def get_soup(url):\n",
    "    if requests.get(url).status_code == 200:\n",
    "        soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "        return soup\n",
    "    else:\n",
    "        return \"EOFError\" #how to return erorr how breakes the program?\n",
    "    \n",
    "def donlowed_img(url, soup, image_num = None, page_folder = None):\n",
    "    image_list = []\n",
    "    for image in soup.find_all(\"img\", src = True):\n",
    "        image_list.append(image)\n",
    "    #choiced_imeges = set()\n",
    "    if not os.path.exists(page_folder):\n",
    "        os.makedirs(urlparse(url).netloc.replace(\".\", \"_\"), exist_ok=True)\n",
    "    #choiced_imeges.add(soup.find_all(soup.find_all(\"img\", src = True)))\n",
    "    choiced_imeges = random.choices(image_list, k = min(image_num, len(image_list)))\n",
    "    for image in choiced_imeges:  \n",
    "        file_name = image[\"alt\"] #simcha\n",
    "        file_url = urljoin(url, image[\"src\"])\n",
    "        file_path = os.path.join(page_folder, file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
    "#get_links(url, get_soup(url))\n",
    "donlowed_img(url, get_soup(url))\n",
    "\n",
    "def get_links(url, soup, page_num = 5):\n",
    "    \n",
    "    link_list = []\n",
    "    for link in soup.find_all(\"a\", href = True):\n",
    "        if link[\"href\"].startswith(\"/\") and not \":\" in link[\"href\"]:\n",
    "            link_list.append(urljoin(url, link[\"href\"]))\n",
    "    choiced_links = random.choices(link_list, k = min(page_num, len(link_list)))\n",
    "    return choiced_links\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
    "get_links(url, get_soup(url))\n",
    "#donlowed_img(url, get_soup(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
